{"meta":{"title":"谢昊璋的博客","subtitle":"","description":"","author":"谢昊璋","url":"http://yoursite.com","root":"/"},"pages":[{"title":"分类","date":"2020-08-28T14:49:15.000Z","updated":"2020-08-30T08:50:50.396Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-08-28T14:46:49.000Z","updated":"2020-08-30T06:06:48.530Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"在树莓派上体验使用NCS2实现对象检测加速推理","slug":"树莓派使用OpenVINO推理YOLOv5","date":"2022-03-01T15:21:12.000Z","updated":"2022-03-18T16:10:41.130Z","comments":true,"path":"2022/03/01/树莓派使用OpenVINO推理YOLOv5/","link":"","permalink":"http://yoursite.com/2022/03/01/%E6%A0%91%E8%8E%93%E6%B4%BE%E4%BD%BF%E7%94%A8OpenVINO%E6%8E%A8%E7%90%86YOLOv5/","excerpt":"","text":"系统版本与依赖 Windows 10 64bit Raspbian 64bit for Raspberry Pi 4B OpenVINO_2021.2.185 VS2019 一、 YOLOv5目标检测1.1 环境测试YOLOv5源码地址： https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov5 克隆项目及配置环境 git clone https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov5.gitcd yolov5pip install -r requirements.txt 测试 python detect.py --weights yolov5n.pt --source data&#x2F;images&#x2F;bus.jpg --img 640 [ Speed: 1.0ms pre-process, 120.7ms inference, 7.0ms NMS per image at shape (1, 3, 640, 640) 1.2 模型导出为实现YOLOv5模型的C端部署，我们将pytorch模型文件转换为开放模型格式ONNX 或者OpenVINO的IR文件。 # 使用Yolov5项目中的脚本转换python models/export.py --weights yolov5s.pt --img 640 --batch 1# 使用OpenVINO的model optimizer工具完成模型转换python mo_onnx.py --input_model E:\\YOLOv5_OpenVINO\\YOLOv5n_openvino\\model\\yolov5n.onnx 二、OpenVINO环境配置相较于学术界更看重的模型精度要求，工业界则是更注重于模型的落地部署。一般来说，使用Python可以更容易地完成模型的训练以及推理演示，但是在实际生产环境中Python的可移植性以及模型前向推理的速度都不如C++。Intel推出的OpenVINO就是一个可以解决模型部署困难问题的Pipeline工具集，同时可以兼容各种开源框架训练好的模型，拥有算法模型上线部署的各种能力，使用OpenVINO工具套件，可以轻松地将深度学习模型部署在Intel的硬件产品上。 对于复杂的深度学习算法，即使有OpenVINO的AI推理性能优化的加持，树莓派的算力依然显得捉襟见肘，考虑到实际应用场景，轻量级的网络往往是很好的解决方案，除此之外Intel的二代神经计算棒也可以为此提供另一种解决方案。 Intel二代神经计算棒由Intel Movidius X VPU提供支持，可提供业界领先的性能、功率和功耗。该神经计算棒支持OpenVINO，与树莓派搭配后可以使用该计算棒推理深度学习模型。 2.1 windows端OpenVINO安装及测试参考官方文档完成OpenVINO安装。 model_optimizer 配置 cd C:\\Program Files (x86)\\Intel\\openvino_2021.2.185\\binsetupvars.batcd C:\\Program Files (x86)\\Intel\\openvino_2021.2.185\\deployment_tools\\model_optimizer\\install_prerequisitesinstall_prerequisites.bat 通过security_barrier_camera测试demo验证环境 C:\\Program Files (x86)\\Intel\\openvino_2021.2.185\\deployment_tools\\demodemo_security_barrier_camera.bat 2.3 Raspbian上OpenVINO的安装与测试参考文档：https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_raspbian.html OpenVINO版本：l_openvino_toolkit_runtime_raspbian_p_2021.2.185 此版本是官方发布的适用于Raspbian的OpenVINO toolkit，如果是Raspbian系统则不建议使用Ubuntu版本的OpenVINO套件。 tar -xf l_openvino_toolkit_runtime_raspbian_p_2021.2.185.tgzecho &quot;&#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;bin&#x2F;setupvars.sh&quot; &gt;&gt; ~&#x2F;.bashrcsudo usermod -a -G users &quot;$(whoami)&quot; 通过人脸demo验证环境 # 临时环境变量source ~&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;bin&#x2F;setupvars.sh# NCS2的USB规则sh &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;install_dependencies&#x2F;install_NCS_udev_rules.sh # 找一个目录mkdir buildcd buildcmake -DCMAKE_BUILD_TYPE&#x3D;Release -DCMAKE_CXX_FLAGS&#x3D;&quot;-march&#x3D;armv7-a&quot; &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;deployment_tools&#x2F;inference_engine&#x2F;samples&#x2F;cppmake -j2 object_detection_sample_ssdwget --no-check-certificate https:&#x2F;&#x2F;download.01.org&#x2F;opencv&#x2F;2020&#x2F;openvinotoolkit&#x2F;2020.1&#x2F;open_model_zoo&#x2F;models_bin&#x2F;1&#x2F;face-detection-adas-0001&#x2F;FP16&#x2F;face-detection-adas-0001.binwget --no-check-certificate https:&#x2F;&#x2F;download.01.org&#x2F;opencv&#x2F;2020&#x2F;openvinotoolkit&#x2F;2020.1&#x2F;open_model_zoo&#x2F;models_bin&#x2F;1&#x2F;face-detection-adas-0001&#x2F;FP16&#x2F;face-detection-adas-0001.xml.&#x2F;armv7l&#x2F;Release&#x2F;object_detection_sample_ssd -m face-detection-adas-0001.xml -d MYRIAD -i &#x2F;home&#x2F;pi&#x2F;YOLOv5n_openvino&#x2F;test&#x2F;bus.jpg 三、基于OpenVINO的YOLOv5前向推理YOLOv5的输出层是3层，分别对应32倍降采样、16倍降采样、8倍降采样。如果输入图像的是640x640，那么三个输出层大小分别是20、40以及80，每个层对应三个尺度的anchor。模型在每个输出层的每个特征点上预测三个框，每个框的维度为cx、cy、w、h、conf以及class。YOLOv5预训练模型基于的COCO数据有80个对象类别，则通过Netron可视化模型可以观察到模型输出如下图所示 解析输出时，循环每个输出层，解析每个特征点对应的 3 个框与相关数据。由于在导出的时候 ONNX 格式文件时模型的推理得到的三个输出层原始结果，所以还需要对每个数据先完成 sigmoid 归一化，然后再计算相关值，得到初始每个对象的检测框之后，做非最大抑制筛掉冗杂数据后，就得到了最终的预测框。解析输出层部分的代码如下： for (int i = 0; i &lt; side_square; ++i) &#123; for (int c = 0; c &lt; out_c; c++) &#123; int row = i / side_h; int col = i % side_h; int object_index = c*side_data_square + row*side_data_w + col*side_data; // 阈值过滤 float conf = sigmoid_function(output_blob[object_index + 4]); if (conf &lt; 0.25) &#123; continue; &#125; // 解析cx, cy, width, height float x = (sigmoid_function(output_blob[object_index]) * 2 - 0.5 + col)*stride; float y = (sigmoid_function(output_blob[object_index + 1]) * 2 - 0.5 + row)*stride; float w = pow(sigmoid_function(output_blob[object_index + 2]) * 2, 2)*anchors[anchor_index + c * 2]; float h = pow(sigmoid_function(output_blob[object_index + 3]) * 2, 2)*anchors[anchor_index + c * 2 + 1]; float max_prob = -1; int class_index = -1; // 解析类别 for (int d = 5; d &lt; 85; d++) &#123; float prob = sigmoid_function(output_blob[object_index + d]); if (prob &gt; max_prob) &#123; max_prob = prob; class_index = d - 5; &#125; &#125; // 转换为top-left, bottom-right坐标 int x1 = saturate_cast&lt;int&gt;((x - w / 2) * scale_x); // top left x int y1 = saturate_cast&lt;int&gt;((y - h / 2) * scale_y); // top left y int x2 = saturate_cast&lt;int&gt;((x + w / 2) * scale_x); // bottom right x int y2 = saturate_cast&lt;int&gt;((y + h / 2) * scale_y); // bottom right y // 解析输出 classIds.push_back(class_index); confidences.push_back((float)conf); boxes.push_back(Rect(x1, y1, x2 - x1, y2 - y1)); // rectangle(src, Rect(x1, y1, x2 - x1, y2 - y1), Scalar(255, 0, 255), 2, 8, 0); &#125;&#125; Yolov5在GPU上检测效果如下图所示： 四、Cmake编译CMakeList.txt cmake_minimum_required(VERSION 2.8.3)project(OpenVINO_TEST)set(OPENVINO_INCLUDE &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;inference_engine&#x2F;include)set(OPENCV_INCLUDE &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;opencv&#x2F;include)set(OPENVINO_LIB &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;inference_engine&#x2F;lib&#x2F;armv7l)set(OPENCV_LIB &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;opencv&#x2F;lib)include_directories($&#123;OPENVINO_INCLUDE&#125; $&#123;OPENCV_INCLUDE&#125;)link_directories($&#123;OPENVINO_LIB&#125; $&#123;OPENCV_LIB&#125;)add_executable(main main.cpp)target_link_libraries(main HeteroPlugin inference_engine inference_engine_c_api inference_engine_nn_builder inference_engine_preproc myriadPlugin)target_link_libraries(main opencv_calib3d opencv_core opencv_dnn opencv_features2d opencv_flann opencv_gapi opencv_highgui opencv_imgcodecs opencv_imgproc opencv_ml opencv_objdetect opencv_photo opencv_stitching opencv_video opencv_videoio opencv_videoio_ffmpeg opencv_videoio_gstreamer)#add_definitions(-D_GLIBCXX_USE_CXX11_ABI&#x3D;0) 编译 mkdir buildcd buildcmake -DCMAKE_BUILD_TYPE&#x3D;Release ..make.&#x2F;main 五、使用OpenVINO的POT组件量化yolov5模型5.1 环境准备安装accuracy_check cd C:\\Program Files (x86)\\Intel\\openvino_2021.2.185\\deployment_tools\\open_model_zoo\\tools\\accuracy_checkerpython setup.py install 安装pot cd C:\\Program Files (x86)\\Intel\\openvino_2021.2.185\\deployment_tools\\tools\\post_training_optimization_toolkitpython setup.py install 验证 accuracy_check -hpot -h 5.2 数据裁剪coco数据集下载：Dataset Preparation Guide — OpenVINO™ documentation — Version(latest) cut_dataset.py 脚本准备 Cut Datasets — OpenVINO™ documentation — Version(2021.4) python C:&#x2F;Work&#x2F;cut_dataset.py --source_images_archive_dir&#x3D;C:&#x2F;Work&#x2F;val2017.zip --source_annotations_archive_dir&#x3D;C:&#x2F;Work&#x2F;annotations_trainval2017.zip --output_size&#x3D;200 --output_archive_dir&#x3D;C:&#x2F;Work&#x2F;subsets --first_image&#x3D;10 --dataset_type&#x3D;coco 5.3 accuracy checker测试精度配置文件yolov5_640_ac.yml为： models: - name: yolo_v5 launchers: - framework: dlsdk tags: - FP32 model: yolov5s.xml weights: yolov5s.bin adapter: type: pytorch_yolo anchors: &quot;10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326&quot; num: 3 coords: 4 classes: 80 threshold: 0.001 anchor_masks: [[0, 1, 2], [3, 4, 5], [6, 7, 8]] raw_output: True outputs: - Conv_198 - Conv_201 - Conv_204 datasets: - name: ms_coco_detection_80_class_without_background preprocessing: - type: resize size: 640 postprocessing: - type: resize_prediction_boxes - type: filter apply_to: prediction min_confidence: 0.001 remove_filtered: true - type: nms overlap: 0.5 - type: clip_boxes apply_to: prediction metrics: - type: map integral: 11point ignore_difficult: true presenter: print_scalar - name: AP@0.5 type: coco_precision max_detections: 100 threshold: 0.5 - name: AP@0.5:0.05:95 type: coco_precision max_detections: 100 threshold: &#39;0.5:0.05:0.95&#39; accuracy_check -c yolov5_640_ac.yml -s .&#x2F; -td CPU 5.4 POT量化yolov5s_int8_simple.json文件 &#123; &quot;model&quot;: &#123; &quot;model_name&quot;: &quot;yolov5s_int8_cpu&quot;, &quot;model&quot;: &quot;E:&#x2F;FP32_to_int8&#x2F;yolov5s_test.xml&quot;, &quot;weights&quot;: &quot;E:&#x2F;FP32_to_int8&#x2F;yolov5s_test.bin&quot; &#125;, &quot;engine&quot;: &#123; &quot;type&quot;: &quot;simplified&quot;, &#x2F;&#x2F; you can specify path to directory with images or video file &#x2F;&#x2F; also you can specify template for file names to filter images to load &#x2F;&#x2F; templates are unix style &quot;data_source&quot;: &quot;val2017&quot; &#125;, &quot;compression&quot;: &#123; &quot;target_device&quot;: &quot;CPU&quot;, &quot;algorithms&quot;: [ &#123; &quot;name&quot;: &quot;DefaultQuantization&quot;, &quot;params&quot;: &#123; &quot;preset&quot;: &quot;performance&quot;, &quot;stat_subset_size&quot;: 128 &#125; &#125; ] &#125;&#125; pot -c .&#x2F;yolov5s_int8_simple.json 量化后的IR模型如图所示： 六、轻量级模型SSDSSD，全称Single Shot MultiBox Detector,模型推理计算得输出格式为：1x1xNx7,第四个维度的七个值表示[id, label, conf, x_min, y_min, x_max, y_max] 输出层解析代码如下： for (auto&amp; item : output_info) &#123; auto output_name &#x3D; item.first; auto output &#x3D; infer_request.GetBlob(output_name); const float* detection_out &#x3D; static_cast&lt;PrecisionTrait&lt;Precision::FP32&gt;::value_type*&gt;(output-&gt;buffer()); const SizeVector outputDims &#x3D; output-&gt;getTensorDesc().getDims(); &#x2F;&#x2F;std::cout &lt;&lt; outputDims[2] &lt;&lt; &quot;x&quot; &lt;&lt; outputDims[3] &lt;&lt; std::endl; const int max_count &#x3D; outputDims[2]; cout &lt;&lt; &quot;max_count&quot; &lt;&lt; max_count &lt;&lt; endl; const int object_size &#x3D; outputDims[3]; for (int n &#x3D; 0; n &lt; max_count; n++) &#123; float label &#x3D; detection_out[n * object_size + 1]; float confidence &#x3D; detection_out[n * object_size + 2]; float xmin &#x3D; detection_out[n * object_size + 3] * sx; float ymin &#x3D; detection_out[n * object_size + 4] * sy; float xmax &#x3D; detection_out[n * object_size + 5] * sx; float ymax &#x3D; detection_out[n * object_size + 6] * sy; if (confidence &gt; 0.7) &#123; printf(&quot;label id : %d, label name: %s confidence: %f\\n&quot;, static_cast&lt;int&gt;(label), coco_labels[static_cast&lt;int&gt;(label)], confidence); cv::Rect box; box.x &#x3D; static_cast&lt;int&gt;(xmin); box.y &#x3D; static_cast&lt;int&gt;(ymin); box.width &#x3D; static_cast&lt;int&gt;(xmax - xmin); box.height &#x3D; static_cast&lt;int&gt;(ymax - ymin); cv::rectangle(frame, box, cv::Scalar(0, 0, 255), 2, 8, 0); cv::putText(frame, coco_labels[static_cast&lt;int&gt;(label)], box.tl(), cv::FONT_HERSHEY_SIMPLEX, 1.0, cv::Scalar(0, 0, 255), 2, 8); &#125; &#125; &#125; 在CPU上推理：","categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]}],"categories":[{"name":"技术文档","slug":"技术文档","permalink":"http://yoursite.com/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]}