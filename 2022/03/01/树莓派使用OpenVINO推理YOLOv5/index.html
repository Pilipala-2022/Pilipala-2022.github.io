<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>在树莓派上体验使用NCS2实现对象检测加速推理 | 谢昊璋的博客</title><meta name="description" content="系统版本与依赖  Windows 10 64bit  Raspbian 64bit for Raspberry Pi 4B  OpenVINO_2021.2.185  VS2019   一、 YOLOv5目标检测1.1 环境测试YOLOv5源码地址： https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov5  克隆项目及配置环境 git c"><meta name="keywords" content="深度学习"><meta name="author" content="谢昊璋"><meta name="copyright" content="谢昊璋"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yoursite.com/2022/03/01/%E6%A0%91%E8%8E%93%E6%B4%BE%E4%BD%BF%E7%94%A8OpenVINO%E6%8E%A8%E7%90%86YOLOv5/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><meta property="og:type" content="article"><meta property="og:title" content="在树莓派上体验使用NCS2实现对象检测加速推理"><meta property="og:url" content="http://yoursite.com/2022/03/01/%E6%A0%91%E8%8E%93%E6%B4%BE%E4%BD%BF%E7%94%A8OpenVINO%E6%8E%A8%E7%90%86YOLOv5/"><meta property="og:site_name" content="谢昊璋的博客"><meta property="og:description" content="系统版本与依赖  Windows 10 64bit  Raspbian 64bit for Raspberry Pi 4B  OpenVINO_2021.2.185  VS2019   一、 YOLOv5目标检测1.1 环境测试YOLOv5源码地址： https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov5  克隆项目及配置环境 git c"><meta property="og:image" content="http://yoursite.com/person/6.jpg"><meta property="article:published_time" content="2022-03-01T15:21:12.000Z"><meta property="article:modified_time" content="2022-03-18T16:10:41.130Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.1.1',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2022-03-19 00:10:41'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 5.1.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">1</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">1</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">1</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li></ul></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81-YOLOv5%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-number">1.</span> <span class="toc-text">一、 YOLOv5目标检测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E7%8E%AF%E5%A2%83%E6%B5%8B%E8%AF%95"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 环境测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%87%BA"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 模型导出</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81OpenVINO%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">2.</span> <span class="toc-text">二、OpenVINO环境配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-windows%E7%AB%AFOpenVINO%E5%AE%89%E8%A3%85%E5%8F%8A%E6%B5%8B%E8%AF%95"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 windows端OpenVINO安装及测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Raspbian%E4%B8%8AOpenVINO%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-number">2.2.</span> <span class="toc-text">2.3 Raspbian上OpenVINO的安装与测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%9F%BA%E4%BA%8EOpenVINO%E7%9A%84YOLOv5%E5%89%8D%E5%90%91%E6%8E%A8%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">三、基于OpenVINO的YOLOv5前向推理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Cmake%E7%BC%96%E8%AF%91"><span class="toc-number">4.</span> <span class="toc-text">四、Cmake编译</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E4%BD%BF%E7%94%A8OpenVINO%E7%9A%84POT%E7%BB%84%E4%BB%B6%E9%87%8F%E5%8C%96yolov5%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.</span> <span class="toc-text">五、使用OpenVINO的POT组件量化yolov5模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 环境准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%95%B0%E6%8D%AE%E8%A3%81%E5%89%AA"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 数据裁剪</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-accuracy-checker%E6%B5%8B%E8%AF%95%E7%B2%BE%E5%BA%A6"><span class="toc-number">5.3.</span> <span class="toc-text">5.3 accuracy checker测试精度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-POT%E9%87%8F%E5%8C%96"><span class="toc-number">5.4.</span> <span class="toc-text">5.4 POT量化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%A8%A1%E5%9E%8BSSD"><span class="toc-number">6.</span> <span class="toc-text">六、轻量级模型SSD</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(/person/6.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">谢昊璋的博客</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li></ul></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">在树莓派上体验使用NCS2实现对象检测加速推理</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-01T15:21:12.000Z" title="发表于 2022-03-01 23:21:12">2022-03-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-18T16:10:41.130Z" title="更新于 2022-03-19 00:10:41">2022-03-19</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3/">技术文档</a></span></div><div class="meta-secondline"> </div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><p><strong>系统版本与依赖</strong></p>
<ul>
<li><p>Windows 10 64bit</p>
</li>
<li><p>Raspbian 64bit for Raspberry Pi 4B</p>
</li>
<li><p>OpenVINO_2021.2.185</p>
</li>
<li><p>VS2019</p>
</li>
</ul>
<h2 id="一、-YOLOv5目标检测"><a href="#一、-YOLOv5目标检测" class="headerlink" title="一、 YOLOv5目标检测"></a>一、 YOLOv5目标检测</h2><h3 id="1-1-环境测试"><a href="#1-1-环境测试" class="headerlink" title="1.1 环境测试"></a>1.1 环境测试</h3><p>YOLOv5源码地址：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov5</span><br></pre></td></tr></table></figure>

<p>克隆项目及配置环境</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov5.git</span><br><span class="line">cd yolov5</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p>测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python detect.py --weights yolov5n.pt --source data&#x2F;images&#x2F;bus.jpg --im</span><br><span class="line">g 640</span><br></pre></td></tr></table></figure>

<p>[<img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b1B0iR.jpg" alt="b1B0iR.jpg" style="zoom:50%;" /></p>
<p>Speed: 1.0ms pre-process, 120.7ms inference, 7.0ms NMS per image at shape (1, 3, 640, 640)</p>
<h3 id="1-2-模型导出"><a href="#1-2-模型导出" class="headerlink" title="1.2 模型导出"></a>1.2 模型导出</h3><p>为实现YOLOv5模型的C端部署，我们将pytorch模型文件转换为开放模型格式ONNX 或者OpenVINO的IR文件。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用Yolov5项目中的脚本转换</span></span><br><span class="line">python models/export.py --weights yolov5s.pt --img <span class="number">640</span> --batch <span class="number">1</span></span><br><span class="line"><span class="comment"># 使用OpenVINO的model optimizer工具完成模型转换</span></span><br><span class="line">python mo_onnx.py --input_model E:\YOLOv5_OpenVINO\YOLOv5n_openvino\model\yolov5n.onnx</span><br></pre></td></tr></table></figure>

<h2 id="二、OpenVINO环境配置"><a href="#二、OpenVINO环境配置" class="headerlink" title="二、OpenVINO环境配置"></a>二、OpenVINO环境配置</h2><p>相较于学术界更看重的模型精度要求，工业界则是更注重于模型的落地部署。一般来说，使用Python可以更容易地完成模型的训练以及推理演示，但是在实际生产环境中Python的可移植性以及模型前向推理的速度都不如C++。Intel推出的OpenVINO就是一个可以解决模型部署困难问题的Pipeline工具集，同时可以兼容各种开源框架训练好的模型，拥有算法模型上线部署的各种能力，使用OpenVINO工具套件，可以轻松地将深度学习模型部署在Intel的硬件产品上。</p>
<p>对于复杂的深度学习算法，即使有OpenVINO的AI推理性能优化的加持，树莓派的算力依然显得捉襟见肘，考虑到实际应用场景，轻量级的网络往往是很好的解决方案，除此之外Intel的二代神经计算棒也可以为此提供另一种解决方案。</p>
<p>Intel二代神经计算棒由Intel Movidius X VPU提供支持，可提供业界领先的性能、功率和功耗。该神经计算棒支持OpenVINO，与树莓派搭配后可以使用该计算棒推理深度学习模型。</p>
<h3 id="2-1-windows端OpenVINO安装及测试"><a href="#2-1-windows端OpenVINO安装及测试" class="headerlink" title="2.1 windows端OpenVINO安装及测试"></a>2.1 windows端OpenVINO安装及测试</h3><p>参考官方文档完成OpenVINO安装。</p>
<p><strong>model_optimizer 配置</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd C:\Program Files (x86)\Intel\openvino_2021.2.185\bin</span><br><span class="line">setupvars.bat</span><br><span class="line">cd C:\Program Files (x86)\Intel\openvino_2021.2.185\deployment_tools\model_optimizer\install_prerequisites</span><br><span class="line">install_prerequisites.bat</span><br></pre></td></tr></table></figure>

<p><strong>通过security_barrier_camera测试demo验证环境</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Program Files (x86)\Intel\openvino_2021.2.185\deployment_tools\demo</span><br><span class="line">demo_security_barrier_camera.bat</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/b1rW8I"><img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b1rW8I.md.png" alt="b1rW8I.md.png" style="zoom: 50%;" /></a>    </p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/b1s9ZF"><img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b1s9ZF.md.png" alt="b1s9ZF.md.png"></a></p>
<h3 id="2-3-Raspbian上OpenVINO的安装与测试"><a href="#2-3-Raspbian上OpenVINO的安装与测试" class="headerlink" title="2.3 Raspbian上OpenVINO的安装与测试"></a>2.3 Raspbian上OpenVINO的安装与测试</h3><p>参考文档：<a target="_blank" rel="noopener" href="https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_raspbian.html">https://docs.openvino.ai/latest/openvino_docs_install_guides_installing_openvino_raspbian.html</a></p>
<p>OpenVINO版本：l_openvino_toolkit_runtime_raspbian_p_2021.2.185</p>
<p>此版本是官方发布的适用于Raspbian的OpenVINO toolkit，如果是Raspbian系统则不建议使用Ubuntu版本的OpenVINO套件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -xf l_openvino_toolkit_runtime_raspbian_p_2021.2.185.tgz</span><br><span class="line">echo &quot;&#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;bin&#x2F;setupvars.sh&quot; &gt;&gt; ~&#x2F;.bashrc</span><br><span class="line">sudo usermod -a -G users &quot;$(whoami)&quot;</span><br></pre></td></tr></table></figure>

<p><strong>通过人脸demo验证环境</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 临时环境变量</span><br><span class="line">source ~&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;bin&#x2F;setupvars.sh</span><br><span class="line"># NCS2的USB规则</span><br><span class="line">sh &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;install_dependencies&#x2F;install_NCS_udev_rules.sh</span><br><span class="line"> </span><br><span class="line"># 找一个目录</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake -DCMAKE_BUILD_TYPE&#x3D;Release -DCMAKE_CXX_FLAGS&#x3D;&quot;-march&#x3D;armv7-a&quot; &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;l_openvino_toolkit_runtime_raspbian_p_2021.2.185&#x2F;deployment_tools&#x2F;inference_engine&#x2F;samples&#x2F;cpp</span><br><span class="line">make -j2 object_detection_sample_ssd</span><br><span class="line">wget --no-check-certificate https:&#x2F;&#x2F;download.01.org&#x2F;opencv&#x2F;2020&#x2F;openvinotoolkit&#x2F;2020.1&#x2F;open_model_zoo&#x2F;models_bin&#x2F;1&#x2F;face-detection-adas-0001&#x2F;FP16&#x2F;face-detection-adas-0001.bin</span><br><span class="line">wget --no-check-certificate https:&#x2F;&#x2F;download.01.org&#x2F;opencv&#x2F;2020&#x2F;openvinotoolkit&#x2F;2020.1&#x2F;open_model_zoo&#x2F;models_bin&#x2F;1&#x2F;face-detection-adas-0001&#x2F;FP16&#x2F;face-detection-adas-0001.xml</span><br><span class="line"></span><br><span class="line">.&#x2F;armv7l&#x2F;Release&#x2F;object_detection_sample_ssd -m face-detection-adas-0001.xml -d MYRIAD -i &#x2F;home&#x2F;pi&#x2F;YOLOv5n_openvino&#x2F;test&#x2F;bus.jpg</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/b1gUcn"><img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b1gUcn.md.png" alt="b1gUcn.md.png"></a></p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/b1g0BV"><img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b1g0BV.md.png" alt="b1g0BV.md.png"></a></p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/b1grAU"><img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b1grAU.md.png" alt="b1grAU.md.png"></a></p>
<h2 id="三、基于OpenVINO的YOLOv5前向推理"><a href="#三、基于OpenVINO的YOLOv5前向推理" class="headerlink" title="三、基于OpenVINO的YOLOv5前向推理"></a>三、基于OpenVINO的YOLOv5前向推理</h2><p>YOLOv5的输出层是3层，分别对应32倍降采样、16倍降采样、8倍降采样。如果输入图像的是640x640，那么三个输出层大小分别是20、40以及80，每个层对应三个尺度的anchor。模型在每个输出层的每个特征点上预测三个框，每个框的维度为cx、cy、w、h、conf以及class。YOLOv5预训练模型基于的COCO数据有80个对象类别，则通过Netron可视化模型可以观察到模型输出如下图所示</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/b16Fjx"><img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b16Fjx.md.png" alt="b16Fjx.md.png"></a></p>
<p>解析输出时，循环每个输出层，解析每个特征点对应的 3 个框与相关数据。由于在导出的时候 ONNX 格式文件时模型的推理得到的三个输出层原始结果，所以还需要对每个数据先完成 sigmoid 归一化，然后再计算相关值，得到初始每个对象的检测框之后，做非最大抑制筛掉冗杂数据后，就得到了最终的预测框。解析输出层部分的代码如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; side_square; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> c = <span class="number">0</span>; c &lt; out_c; c++) &#123;</span><br><span class="line">        <span class="keyword">int</span> row = i / side_h;</span><br><span class="line">        <span class="keyword">int</span> col = i % side_h;</span><br><span class="line">        <span class="keyword">int</span> object_index = c*side_data_square + row*side_data_w + col*side_data;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 阈值过滤</span></span><br><span class="line">        <span class="keyword">float</span> conf = sigmoid_function(output_blob[object_index + <span class="number">4</span>]);</span><br><span class="line">        <span class="keyword">if</span> (conf &lt; <span class="number">0.25</span>) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 解析cx, cy, width, height</span></span><br><span class="line">        <span class="keyword">float</span> x = (sigmoid_function(output_blob[object_index]) * <span class="number">2</span> - <span class="number">0.5</span> + col)*stride;</span><br><span class="line">        <span class="keyword">float</span> y = (sigmoid_function(output_blob[object_index + <span class="number">1</span>]) * <span class="number">2</span> - <span class="number">0.5</span> + row)*stride;</span><br><span class="line">        <span class="keyword">float</span> w = <span class="built_in">pow</span>(sigmoid_function(output_blob[object_index + <span class="number">2</span>]) * <span class="number">2</span>, <span class="number">2</span>)*anchors[anchor_index + c * <span class="number">2</span>];</span><br><span class="line">        <span class="keyword">float</span> h = <span class="built_in">pow</span>(sigmoid_function(output_blob[object_index + <span class="number">3</span>]) * <span class="number">2</span>, <span class="number">2</span>)*anchors[anchor_index + c * <span class="number">2</span> + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">float</span> max_prob = <span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">int</span> class_index = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 解析类别</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> d = <span class="number">5</span>; d &lt; <span class="number">85</span>; d++) &#123;</span><br><span class="line">            <span class="keyword">float</span> prob = sigmoid_function(output_blob[object_index + d]);</span><br><span class="line">            <span class="keyword">if</span> (prob &gt; max_prob) &#123;</span><br><span class="line">                max_prob = prob;</span><br><span class="line">                class_index = d - <span class="number">5</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 转换为top-left, bottom-right坐标</span></span><br><span class="line">        <span class="keyword">int</span> x1 = saturate_cast&lt;<span class="keyword">int</span>&gt;((x - w / <span class="number">2</span>) * scale_x);  <span class="comment">// top left x</span></span><br><span class="line">        <span class="keyword">int</span> y1 = saturate_cast&lt;<span class="keyword">int</span>&gt;((y - h / <span class="number">2</span>) * scale_y);  <span class="comment">// top left y</span></span><br><span class="line">        <span class="keyword">int</span> x2 = saturate_cast&lt;<span class="keyword">int</span>&gt;((x + w / <span class="number">2</span>) * scale_x);  <span class="comment">// bottom right x</span></span><br><span class="line">        <span class="keyword">int</span> y2 = saturate_cast&lt;<span class="keyword">int</span>&gt;((y + h / <span class="number">2</span>) * scale_y); <span class="comment">// bottom right y</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 解析输出</span></span><br><span class="line">        classIds.push_back(class_index);</span><br><span class="line">        confidences.push_back((<span class="keyword">float</span>)conf);</span><br><span class="line">        boxes.push_back(Rect(x1, y1, x2 - x1, y2 - y1));</span><br><span class="line">        <span class="comment">// rectangle(src, Rect(x1, y1, x2 - x1, y2 - y1), Scalar(255, 0, 255), 2, 8, 0);</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Yolov5在GPU上检测效果如下图所示：</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/b1c8zR"><img src= "/img/loading.gif" data-lazy-src="https://s4.ax1x.com/2022/03/01/b1c8zR.md.png" alt="b1c8zR.md.png"></a></p>
<h2 id="四、Cmake编译"><a href="#四、Cmake编译" class="headerlink" title="四、Cmake编译"></a>四、Cmake编译</h2><p>CMakeList.txt</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 2.8.3)</span><br><span class="line">project(OpenVINO_TEST)</span><br><span class="line">set(OPENVINO_INCLUDE &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;inference_engine&#x2F;include)</span><br><span class="line">set(OPENCV_INCLUDE &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;opencv&#x2F;include)</span><br><span class="line">set(OPENVINO_LIB &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;inference_engine&#x2F;lib&#x2F;armv7l)</span><br><span class="line">set(OPENCV_LIB &#x2F;home&#x2F;pi&#x2F;Downloads&#x2F;openvino_2020&#x2F;opencv&#x2F;lib)</span><br><span class="line">include_directories($&#123;OPENVINO_INCLUDE&#125; $&#123;OPENCV_INCLUDE&#125;)</span><br><span class="line">link_directories($&#123;OPENVINO_LIB&#125; $&#123;OPENCV_LIB&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">add_executable(main main.cpp)</span><br><span class="line">target_link_libraries(main HeteroPlugin inference_engine inference_engine_c_api inference_engine_nn_builder inference_engine_preproc myriadPlugin)</span><br><span class="line">target_link_libraries(main opencv_calib3d opencv_core opencv_dnn opencv_features2d opencv_flann opencv_gapi opencv_highgui opencv_imgcodecs opencv_imgproc opencv_ml opencv_objdetect opencv_photo  opencv_stitching opencv_video opencv_videoio opencv_videoio_ffmpeg opencv_videoio_gstreamer)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#add_definitions(-D_GLIBCXX_USE_CXX11_ABI&#x3D;0)</span><br></pre></td></tr></table></figure>

<p>编译</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">cmake -DCMAKE_BUILD_TYPE&#x3D;Release ..</span><br><span class="line">make</span><br><span class="line">.&#x2F;main</span><br></pre></td></tr></table></figure>



<h2 id="五、使用OpenVINO的POT组件量化yolov5模型"><a href="#五、使用OpenVINO的POT组件量化yolov5模型" class="headerlink" title="五、使用OpenVINO的POT组件量化yolov5模型"></a>五、使用OpenVINO的POT组件量化yolov5模型</h2><h3 id="5-1-环境准备"><a href="#5-1-环境准备" class="headerlink" title="5.1 环境准备"></a>5.1 环境准备</h3><p><strong>安装accuracy_check</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd C:\Program Files (x86)\Intel\openvino_2021.2.185\deployment_tools\open_model_zoo\tools\accuracy_checker</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

<p><strong>安装pot</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd C:\Program Files (x86)\Intel\openvino_2021.2.185\deployment_tools\tools\post_training_optimization_toolkit</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>

<p><strong>验证</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">accuracy_check -h</span><br><span class="line">pot -h</span><br></pre></td></tr></table></figure>



<h3 id="5-2-数据裁剪"><a href="#5-2-数据裁剪" class="headerlink" title="5.2 数据裁剪"></a>5.2 数据裁剪</h3><p>coco数据集下载：<a target="_blank" rel="noopener" href="https://docs.openvino.ai/latest/omz_data_datasets.html">Dataset Preparation Guide — OpenVINO™ documentation — Version(latest)</a></p>
<p>cut_dataset.py 脚本准备 <a target="_blank" rel="noopener" href="https://docs.openvino.ai/2021.4/workbench_docs_Workbench_DG_Download_and_Cut_Datasets.html#coco">Cut Datasets — OpenVINO™ documentation — Version(2021.4)</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python C:&#x2F;Work&#x2F;cut_dataset.py --source_images_archive_dir&#x3D;C:&#x2F;Work&#x2F;val2017.zip --source_annotations_archive_dir&#x3D;C:&#x2F;Work&#x2F;annotations_trainval2017.zip --output_size&#x3D;200 --output_archive_dir&#x3D;C:&#x2F;Work&#x2F;subsets --first_image&#x3D;10 --dataset_type&#x3D;coco</span><br></pre></td></tr></table></figure>



<h3 id="5-3-accuracy-checker测试精度"><a href="#5-3-accuracy-checker测试精度" class="headerlink" title="5.3 accuracy checker测试精度"></a>5.3 accuracy checker测试精度</h3><p>配置文件yolov5_640_ac.yml为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">models:</span><br><span class="line"></span><br><span class="line">  - name: yolo_v5</span><br><span class="line">    launchers:</span><br><span class="line">      - framework: dlsdk</span><br><span class="line">        tags:</span><br><span class="line">          - FP32</span><br><span class="line">        model: yolov5s.xml</span><br><span class="line">        weights: yolov5s.bin</span><br><span class="line">        adapter:</span><br><span class="line">          type: pytorch_yolo</span><br><span class="line">          anchors: &quot;10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326&quot;</span><br><span class="line">          num: 3</span><br><span class="line">          coords: 4</span><br><span class="line">          classes: 80</span><br><span class="line">          threshold: 0.001</span><br><span class="line">          anchor_masks: [[0, 1, 2], [3, 4, 5], [6, 7, 8]]</span><br><span class="line">          raw_output: True</span><br><span class="line">          outputs:</span><br><span class="line">            - Conv_198</span><br><span class="line">            - Conv_201</span><br><span class="line">            - Conv_204</span><br><span class="line">    datasets:</span><br><span class="line">      - name: ms_coco_detection_80_class_without_background</span><br><span class="line"></span><br><span class="line">        preprocessing:</span><br><span class="line">          - type: resize</span><br><span class="line">            size: 640</span><br><span class="line">        postprocessing:</span><br><span class="line">          - type: resize_prediction_boxes</span><br><span class="line">          - type: filter</span><br><span class="line">            apply_to: prediction</span><br><span class="line">            min_confidence: 0.001</span><br><span class="line">            remove_filtered: true</span><br><span class="line">          - type: nms</span><br><span class="line">            overlap: 0.5</span><br><span class="line">          - type: clip_boxes</span><br><span class="line">            apply_to: prediction</span><br><span class="line">        metrics:</span><br><span class="line">          - type: map</span><br><span class="line">            integral: 11point</span><br><span class="line">            ignore_difficult: true</span><br><span class="line">            presenter: print_scalar</span><br><span class="line">          - name: AP@0.5</span><br><span class="line">            type: coco_precision</span><br><span class="line">            max_detections: 100</span><br><span class="line">            threshold: 0.5</span><br><span class="line">          - name: AP@0.5:0.05:95</span><br><span class="line">            type: coco_precision</span><br><span class="line">            max_detections: 100</span><br><span class="line">            threshold: &#39;0.5:0.05:0.95&#39;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">accuracy_check -c yolov5_640_ac.yml  -s .&#x2F; -td CPU</span><br></pre></td></tr></table></figure>



<h3 id="5-4-POT量化"><a href="#5-4-POT量化" class="headerlink" title="5.4 POT量化"></a>5.4 POT量化</h3><p>yolov5s_int8_simple.json文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;model&quot;: &#123;</span><br><span class="line">        &quot;model_name&quot;: &quot;yolov5s_int8_cpu&quot;,</span><br><span class="line">        &quot;model&quot;: &quot;E:&#x2F;FP32_to_int8&#x2F;yolov5s_test.xml&quot;,</span><br><span class="line">        &quot;weights&quot;: &quot;E:&#x2F;FP32_to_int8&#x2F;yolov5s_test.bin&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;engine&quot;: &#123;</span><br><span class="line">        &quot;type&quot;: &quot;simplified&quot;,</span><br><span class="line">        &#x2F;&#x2F; you can specify path to directory with images or video file</span><br><span class="line">        &#x2F;&#x2F; also you can specify template for file names to filter images to load</span><br><span class="line">        &#x2F;&#x2F; templates are unix style</span><br><span class="line">        &quot;data_source&quot;: &quot;val2017&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;compression&quot;: &#123;</span><br><span class="line">        &quot;target_device&quot;: &quot;CPU&quot;,</span><br><span class="line">        &quot;algorithms&quot;: [</span><br><span class="line">            &#123;</span><br><span class="line">                &quot;name&quot;: &quot;DefaultQuantization&quot;,</span><br><span class="line">                &quot;params&quot;: &#123;</span><br><span class="line">                    &quot;preset&quot;: &quot;performance&quot;,</span><br><span class="line">                    &quot;stat_subset_size&quot;: 128</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pot -c .&#x2F;yolov5s_int8_simple.json</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/qP7cB6"><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2022/03/18/qP7cB6.png" alt="qP7cB6.png"  /></a></p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/qP7WND"><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2022/03/18/qP7WND.png" alt="qP7WND.png"></a></p>
<p>量化后的IR模型如图所示：</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/qP7f4e"><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2022/03/18/qP7f4e.png" alt="qP7f4e.png"></a></p>
<h2 id="六、轻量级模型SSD"><a href="#六、轻量级模型SSD" class="headerlink" title="六、轻量级模型SSD"></a>六、轻量级模型SSD</h2><p>SSD，全称Single Shot MultiBox Detector,模型推理计算得输出格式为：1x1xNx7,第四个维度的七个值表示[id, label, conf, x_min, y_min, x_max, y_max]</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/qk20Hg"><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2022/03/18/qk20Hg.png" alt="qk20Hg.png"></a></p>
<p>输出层解析代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for (auto&amp; item : output_info) &#123;</span><br><span class="line">		auto output_name &#x3D; item.first;</span><br><span class="line">		auto output &#x3D; infer_request.GetBlob(output_name);</span><br><span class="line">		const float* detection_out &#x3D; static_cast&lt;PrecisionTrait&lt;Precision::FP32&gt;::value_type*&gt;(output-&gt;buffer());</span><br><span class="line">		const SizeVector outputDims &#x3D; output-&gt;getTensorDesc().getDims();</span><br><span class="line">		&#x2F;&#x2F;std::cout &lt;&lt; outputDims[2] &lt;&lt; &quot;x&quot; &lt;&lt; outputDims[3] &lt;&lt; std::endl;</span><br><span class="line">		const int max_count &#x3D; outputDims[2];</span><br><span class="line">		cout &lt;&lt; &quot;max_count&quot; &lt;&lt; max_count &lt;&lt; endl;</span><br><span class="line">		const int object_size &#x3D; outputDims[3];</span><br><span class="line">		for (int n &#x3D; 0; n &lt; max_count; n++) &#123;</span><br><span class="line">			float label &#x3D; detection_out[n * object_size + 1];</span><br><span class="line">			float confidence &#x3D; detection_out[n * object_size + 2];</span><br><span class="line">			float xmin &#x3D; detection_out[n * object_size + 3] * sx;</span><br><span class="line">			float ymin &#x3D; detection_out[n * object_size + 4] * sy;</span><br><span class="line">			float xmax &#x3D; detection_out[n * object_size + 5] * sx;</span><br><span class="line">			float ymax &#x3D; detection_out[n * object_size + 6] * sy;</span><br><span class="line">			if (confidence &gt; 0.7) &#123;</span><br><span class="line">				printf(&quot;label id : %d, label name: %s confidence: %f\n&quot;, static_cast&lt;int&gt;(label), coco_labels[static_cast&lt;int&gt;(label)], confidence);</span><br><span class="line">				cv::Rect box;</span><br><span class="line">				box.x &#x3D; static_cast&lt;int&gt;(xmin);</span><br><span class="line">				box.y &#x3D; static_cast&lt;int&gt;(ymin);</span><br><span class="line">				box.width &#x3D; static_cast&lt;int&gt;(xmax - xmin);</span><br><span class="line">				box.height &#x3D; static_cast&lt;int&gt;(ymax - ymin);</span><br><span class="line">				cv::rectangle(frame, box, cv::Scalar(0, 0, 255), 2, 8, 0);</span><br><span class="line">				cv::putText(frame, coco_labels[static_cast&lt;int&gt;(label)], box.tl(), cv::FONT_HERSHEY_SIMPLEX, 1.0, cv::Scalar(0, 0, 255), 2, 8);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p>在CPU上推理：</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/qkhJZ8"><img src= "/img/loading.gif" data-lazy-src="https://s1.ax1x.com/2022/03/19/qkhJZ8.md.png" alt="qkhJZ8.md.png"></a></p>
</div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post_share"><div class="social-share" data-image="/person/6.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"></nav></article></main><footer id="footer" style="background-image: url(/person/6.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By 谢昊璋</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="/js/third-party/canvas-nest.js"></script></div></body></html>